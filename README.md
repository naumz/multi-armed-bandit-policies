# multi-armed-bandit-policies
Various policies for MABs simulated in MATLAB

The following are some of the different online learning policies for a single-player multi-armed bandit setting.

1. ucb.m - Auer and Cesa-Bianchi's Upper Confidence Bound (UCB) https://homes.di.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf

2. ucbdelayed.m - A delayed-action version of UCB policy. https://arxiv.org/abs/1206.3582

3. TS.m - To simulate performance of a Thompson Sampling policy for online learning in a multi-armed bandit setting. http://jmlr.org/proceedings/papers/v23/agrawal12/agrawal12.pdf

4. TSdelayed.m - To simulate performance of a delayed-action Thompson Sampling policy for online learning in a multi-armed bandit setting. https://arxiv.org/abs/1505.00553

5. e3.m - To simulate performance of the E3 policy for online learning in a multi-armed bandit setting. https://arxiv.org/abs/1505.00553

Each file is self-contained.
